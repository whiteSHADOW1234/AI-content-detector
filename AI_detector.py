import tkinter as tk
from tkinter import ttk, scrolledtext, messagebox
import threading
import torch
import numpy as np
from transformers import GPT2LMHeadModel, GPT2TokenizerFast

# å®šç¾©å¯é¸çš„æ¨¡å‹å’Œå…¶æ¨™ç±¤
MODEL_OPTIONS = {
    "GPT-2 Small (117M)": "gpt2",
    "GPT-2 Medium (345M)": "gpt2-medium",
    "GPT-2 Large (774M)": "gpt2-large"
}

# --- æ–°å¢ï¼šå®šç¾©é¡è‰²æ¢¯åº¦ ---
# é€™äº›é¡è‰²æ¨™ç±¤å¿…é ˆåœ¨ ScrolledText widget ä¸­é…ç½®
LOSS_TAGS = {
    "low_loss": '#e6ffe6',   # éå¸¸å®¹æ˜“é æ¸¬ (åAI)
    "med_low_loss": '#ffffcc', # å®¹æ˜“é æ¸¬
    "medium_loss": '#ffebcc', # ä¸­ç­‰é›£åº¦
    "high_loss": '#ffcccc',   # è¼ƒé›£é æ¸¬
    "very_high_loss": '#ff8080' # éå¸¸é›£é æ¸¬ (åäºº)
}

class PerplexityApp:
    def __init__(self, root):
        self.root = root
        self.root.title("GPT-2 æ–‡ç« å›°æƒ‘åº¦åˆ†æ (å«æå¤±ç†±åŠ›åœ–)")
        self.root.geometry("850x750") 

        self.model = None
        self.tokenizer = None
        self.current_model_name = MODEL_OPTIONS["GPT-2 Small (117M)"] 

        self._create_widgets()
        self._load_model_async()

    def _clear_input(self):
        """æ¸…ç©ºè¼¸å…¥æ–‡æœ¬æ¡†çš„å…§å®¹"""
        self.input_text.delete("1.0", tk.END)
        self.input_text.tag_remove(tk.ALL, "1.0", tk.END) # æ¸…é™¤æ‰€æœ‰é«˜äº®

    def _create_widgets(self):
        main_frame = ttk.Frame(self.root, padding="15 15 15 15")
        main_frame.pack(fill="both", expand=True)
        main_frame.columnconfigure(0, weight=1)

        # 1. æ¨¡å‹é¸æ“‡å’Œç‹€æ…‹å€åŸŸ
        config_frame = ttk.Frame(main_frame)
        config_frame.grid(row=0, column=0, sticky="ew", pady=(0, 10))
        config_frame.columnconfigure(1, weight=1)
        
        ttk.Label(config_frame, text="é¸æ“‡æ¨¡å‹å¤§å°:", font=('Arial', 10, 'bold')).grid(row=0, column=0, sticky="w", padx=(0, 10))
        
        self.model_var = tk.StringVar(value="GPT-2 Small (117M)")
        self.model_combobox = ttk.Combobox(
            config_frame, 
            textvariable=self.model_var, 
            values=list(MODEL_OPTIONS.keys()),
            state="readonly",
            width=25
        )
        self.model_combobox.grid(row=0, column=1, sticky="w", padx=(0, 10))
        self.model_combobox.bind("<<ComboboxSelected>>", self._on_model_select_change)

        self.status_var = tk.StringVar()
        self.status_var.set("æ­£åœ¨è¼‰å…¥æ¨¡å‹ï¼Œè«‹ç¨å€™...")
        self.status_label = ttk.Label(config_frame, textvariable=self.status_var, font=('Arial', 10, 'italic'), foreground='blue')
        self.status_label.grid(row=0, column=2, sticky="e")
        config_frame.columnconfigure(2, weight=1) 

        self.progress_bar = ttk.Progressbar(main_frame, mode='indeterminate', length=200)
        self.progress_bar.grid(row=1, column=0, sticky="ew", pady=(0, 10))


        # 2. è¼¸å…¥æ–‡æœ¬å€åŸŸæ§åˆ¶
        input_controls_frame = ttk.Frame(main_frame)
        input_controls_frame.grid(row=2, column=0, sticky="ew")
        input_controls_frame.columnconfigure(0, weight=1) 
        
        ttk.Label(input_controls_frame, text="è«‹è¼¸å…¥æ‚¨çš„è‹±æ–‡æ–‡ç« ï¼š", font=('Arial', 12, 'bold')).grid(row=0, column=0, sticky="w", pady=(0, 5))
        
        clear_button = ttk.Button(input_controls_frame, text="æ¸…ç©ºæ–‡æœ¬", command=self._clear_input)
        clear_button.grid(row=0, column=1, sticky="e", padx=(10, 0))

        self.input_text = scrolledtext.ScrolledText(main_frame, wrap=tk.WORD, width=80, height=15, font=('Arial', 10))
        self.input_text.grid(row=3, column=0, sticky="nsew", pady=(0, 10))
        
        # --- è¨­å®š ScrolledText çš„ Tag æ¨£å¼ (é—œéµæ­¥é©Ÿ) ---
        for tag_name, color in LOSS_TAGS.items():
            self.input_text.tag_config(tag_name, background=color)

        self.input_text.bind("<Control-a>", self.select_all_text)
        self.input_text.bind("<Command-a>", self.select_all_text) 

        # 3. è¨ˆç®—æŒ‰éˆ•
        self.calculate_button = ttk.Button(main_frame, text="è¨ˆç®—ä¸¦é«˜äº®é¡¯ç¤ºå›°æƒ‘åº¦", command=self._start_calculation, state=tk.DISABLED)
        self.calculate_button.grid(row=4, column=0, sticky="ew", pady=(0, 20))

        # 4. çµæœé¡¯ç¤ºå€åŸŸ
        ttk.Label(main_frame, text="=== åˆ†æçµæœ ===", font=('Arial', 12, 'bold')).grid(row=5, column=0, sticky="w", pady=(10, 5))

        result_frame = ttk.Frame(main_frame)
        result_frame.grid(row=6, column=0, sticky="ew", padx=10)
        result_frame.columnconfigure(0, weight=1) 

        self.token_count_var = tk.StringVar(value="")
        ttk.Label(result_frame, text="åˆ†æçš„ Token ç¸½æ•¸ï¼š", font=('Arial', 11)).grid(row=0, column=0, sticky="w")
        ttk.Label(result_frame, textvariable=self.token_count_var, font=('Arial', 11, 'bold'), foreground='darkcyan').grid(row=0, column=1, sticky="e")
        
        self.ppl_var = tk.StringVar(value="")
        ttk.Label(result_frame, text="æ•´é«”å¹³å‡å›°æƒ‘åº¦ï¼ˆPPLï¼‰ï¼š", font=('Arial', 11)).grid(row=1, column=0, sticky="w")
        ttk.Label(result_frame, textvariable=self.ppl_var, font=('Arial', 11, 'bold'), foreground='darkgreen').grid(row=1, column=1, sticky="e")

        self.var_loss_var = tk.StringVar(value="")
        ttk.Label(result_frame, text="Token æå¤±è®Šç•°é‡ï¼š", font=('Arial', 11)).grid(row=2, column=0, sticky="w")
        ttk.Label(result_frame, textvariable=self.var_loss_var, font=('Arial', 11, 'bold'), foreground='darkgreen').grid(row=2, column=1, sticky="e")

        ttk.Separator(main_frame, orient='horizontal').grid(row=7, column=0, sticky="ew", pady=(10, 10))

        # åˆ¤æ–·çµæœ
        self.prediction_var = tk.StringVar(value="")
        ttk.Label(main_frame, text="åˆ¤æ–·çµæœï¼š", font=('Arial', 12)).grid(row=8, column=0, sticky="w", padx=(10, 0))
        self.prediction_label = ttk.Label(main_frame, textvariable=self.prediction_var, font=('Arial', 14, 'bold'))
        self.prediction_label.grid(row=8, column=0, sticky="e", padx=(10, 10))

        # --- 5. æ–°å¢é«˜äº®åœ–ä¾‹ (Legend) ---
        ttk.Label(main_frame, text="Token é æ¸¬é›£åº¦ç†±åŠ›åœ–ï¼š", font=('Arial', 10, 'bold')).grid(row=9, column=0, sticky="w", pady=(10, 5))
        
        legend_frame = ttk.Frame(main_frame)
        legend_frame.grid(row=10, column=0, sticky="ew", pady=(0, 5))
        
        legend_text = [
            ("æ˜“é æ¸¬ (AI å‚¾å‘):", "low_loss"),
            ("ä¸­ç­‰é›£åº¦:", "medium_loss"),
            ("é›£é æ¸¬ (äººé¡å‚¾å‘):", "very_high_loss")
        ]
        
        col_idx = 0
        for text, tag in legend_text:
            l = ttk.Label(legend_frame, text=f"â–  {text}", background=LOSS_TAGS[tag], borderwidth=1, relief="solid", padding=(5, 2))
            l.grid(row=0, column=col_idx, padx=5, sticky="w")
            col_idx += 1
            legend_frame.columnconfigure(col_idx - 1, weight=1)

        # åº•éƒ¨èªªæ˜
        ttk.Label(main_frame, text="æç¤ºï¼šæ–‡æœ¬ä¸­çš„é¡è‰²æ¨™è¨˜é¡¯ç¤ºäº†æ¨¡å‹å°æ¯å€‹è©èªé æ¸¬çš„é›£åº¦ï¼ˆæå¤±å€¼ï¼‰ã€‚", font=('Arial', 9, 'italic')).grid(row=11, column=0, sticky="w", pady=(10, 0))
        ttk.Label(main_frame, text="æ³¨æ„ï¼šé€™äº›åˆ¤æ–·é–¾å€¼æ˜¯ç¶“é©—æ€§çš„ï¼Œå¯èƒ½éœ€è¦æ ¹æ“šå¯¦éš›æ‡‰ç”¨èª¿æ•´ã€‚", font=('Arial', 9, 'italic')).grid(row=12, column=0, sticky="w", pady=(0, 5))

        main_frame.rowconfigure(3, weight=1) 

    def select_all_text(self, event=None):
        self.input_text.tag_add("sel", "1.0", "end-1c")
        return "break" 

    def _on_model_select_change(self, event):
        selected_key = self.model_var.get()
        new_model_name = MODEL_OPTIONS.get(selected_key)
        
        if new_model_name != self.current_model_name:
            self.current_model_name = new_model_name
            self._load_model_async()

    def _load_model_async(self):
        # ... (æ¨¡å‹åŠ è¼‰é‚è¼¯ä¸è®Š) ...
        self.calculate_button.config(state=tk.DISABLED)
        self.status_var.set(f"æ­£åœ¨è¼‰å…¥ {self.current_model_name} æ¨¡å‹... è«‹ç¨å€™...")
        self.progress_bar.start(10) 
        self.root.update_idletasks() 

        def load_task():
            try:
                model = GPT2LMHeadModel.from_pretrained(self.current_model_name)
                tokenizer = GPT2TokenizerFast.from_pretrained(self.current_model_name)
                model.eval()
                
                self.model = model
                self.tokenizer = tokenizer
                
                self.root.after(0, self._on_model_loaded, True) 
            except Exception as e:
                self.root.after(0, self._on_model_loaded, False, str(e))

        threading.Thread(target=load_task).start()

    def _on_model_loaded(self, success, error_message=None):
        self.progress_bar.stop()
        if success:
            self.status_var.set(f"æ¨¡å‹ {self.current_model_name} è¼‰å…¥å®Œæˆã€‚")
            self.calculate_button.config(state=tk.NORMAL)
        else:
            self.status_var.set(f"æ¨¡å‹è¼‰å…¥å¤±æ•—: {error_message}")
            messagebox.showerror("éŒ¯èª¤", f"ç„¡æ³•è¼‰å…¥æ¨¡å‹ï¼š{error_message}\nè«‹æª¢æŸ¥ç¶²çµ¡é€£æ¥æˆ–æ¨¡å‹åç¨±ã€‚")
            self.calculate_button.config(state=tk.DISABLED)

    def _start_calculation(self):
        text = self.input_text.get("1.0", "end-1c").strip() 

        if not text:
            messagebox.showwarning("è¼¸å…¥éŒ¯èª¤", "è«‹åœ¨æ–‡æœ¬æ¡†ä¸­è¼¸å…¥æ–‡ç« å¾Œå†è¨ˆç®—ã€‚")
            return

        # è¨ˆç®—å‰æ¸…é™¤æ‰€æœ‰èˆŠçš„é«˜äº®æ¨™ç±¤
        self.input_text.tag_remove(tk.ALL, "1.0", tk.END)

        self.calculate_button.config(state=tk.DISABLED)
        self.status_var.set("æ­£åœ¨è¨ˆç®—ä¸­...è«‹ç¨å€™...")
        self.ppl_var.set("")
        self.var_loss_var.set("")
        self.token_count_var.set("") 
        self.prediction_var.set("")
        self.progress_bar.start(50) 
        self.root.update_idletasks() 

        def calculation_task():
            try:
                avg_ppl, var_token_losses, token_count, prediction_text, offsets, token_losses_np = self._calculate_perplexity(text)
                
                # å°‡è¨ˆç®—çµæœå’Œé«˜äº®æ‰€éœ€æ•¸æ“šå‚³éçµ¦ä¸»åŸ·è¡Œç·’
                self.root.after(0, self._on_calculation_complete, avg_ppl, var_token_losses, token_count, prediction_text, offsets, token_losses_np)
            except Exception as e:
                self.root.after(0, self._on_calculation_error, str(e))

        threading.Thread(target=calculation_task).start()

    def _on_calculation_complete(self, avg_ppl, var_token_losses, token_count, prediction_text, offsets, token_losses_np):
        """è¨ˆç®—å®Œæˆå¾Œæ›´æ–° GUI å’Œæ‡‰ç”¨é«˜äº®"""
        self.progress_bar.stop()
        
        self.token_count_var.set(f"{token_count}")
        self.ppl_var.set(f"{avg_ppl:.2f}" if avg_ppl != float('inf') else "N/A (æ–‡æœ¬éçŸ­)")
        self.var_loss_var.set(f"{var_token_losses:.2f}" if var_token_losses != float('inf') else "N/A (æ–‡æœ¬éçŸ­)")
        self.prediction_var.set(prediction_text)
        self.status_var.set("è¨ˆç®—å®Œæˆï¼Œè«‹æŸ¥çœ‹é«˜äº®çµæœã€‚")
        self.calculate_button.config(state=tk.NORMAL)

        # æ‡‰ç”¨é«˜äº® (æ·±åº¦å­¸ç¿’å¯è¦–åŒ–éƒ¨åˆ†)
        if token_losses_np is not None:
            self._highlight_losses(offsets, token_losses_np)

        # æ ¹æ“šé æ¸¬çµæœèª¿æ•´é æ¸¬æ–‡å­—çš„é¡è‰²
        if "æ¥µé«˜å¯èƒ½æ˜¯AIç”Ÿæˆå…§å®¹" in prediction_text:
            self.prediction_label.config(foreground='red')
        # ... (å…¶é¤˜é¡è‰²é‚è¼¯ä¸è®Š) ...
        elif "å¯èƒ½æ˜¯AIç”Ÿæˆ" in prediction_text:
            self.prediction_label.config(foreground='orange')
        elif "è¼ƒå¯èƒ½æ˜¯äººé¡æ’°å¯«" in prediction_text:
            self.prediction_label.config(foreground='darkblue')
        elif "æ¥µé«˜å¯èƒ½æ˜¯äººé¡æ’°å¯«" in prediction_text:
            self.prediction_label.config(foreground='green')
        else:
            self.prediction_label.config(foreground='purple') 


    def _highlight_losses(self, offsets, token_losses):
        """
        å°‡ Token æå¤±å€¼æ˜ å°„åˆ°é¡è‰²æ¨™ç±¤ï¼Œä¸¦æ‡‰ç”¨æ–¼æ–‡æœ¬æ¡†ã€‚
        é€™ç›´æ¥åæ˜ äº†æ¨¡å‹å°æ¯å€‹è©å½™çš„é æ¸¬ä¿¡å¿ƒã€‚
        """
        if not offsets or not token_losses.size:
            return

        # è¨­ç½®æå¤±å€¼çš„é–¾å€¼ï¼ˆé€™äº›æ˜¯ç¶“é©—æ€§çš„ï¼Œå¯ä»¥æ ¹æ“šæ¨¡å‹è¼¸å‡ºåˆ†ä½ˆèª¿æ•´ï¼‰
        # æå¤±å€¼é€šå¸¸åœ¨ 0 åˆ° 10 ä¹‹é–“ï¼Œä½†æ¥µç«¯å€¼å¯èƒ½æ›´é«˜ã€‚
        q1 = np.percentile(token_losses, 20)
        q2 = np.percentile(token_losses, 50)
        q3 = np.percentile(token_losses, 80)
        q4 = np.percentile(token_losses, 95)
        
        # è¿­ä»£å¾ç¬¬äºŒå€‹ Token é–‹å§‹ï¼ˆç¬¬ä¸€å€‹ Token æ²’æœ‰å‰æ–‡ï¼Œç„¡æ³•è¨ˆç®—æå¤±ï¼‰
        # token_losses çš„é•·åº¦æ¯” offsets å°‘ 1
        for i in range(len(token_losses)):
            loss = token_losses[i]
            
            # offsets æ˜¯é‡å°æ•´å€‹è¼¸å…¥åºåˆ—çš„ï¼Œæˆ‘å€‘éœ€è¦å–å¾ç¬¬äºŒå€‹ Token é–‹å§‹çš„ offset
            # å› ç‚ºæå¤±æ˜¯å°æ‡‰æ–¼ "shift_labels" (å³ token[1:])
            start_char, end_char = offsets[i + 1] 

            # ç¢ºä¿åç§»é‡æ˜¯æœ‰æ•ˆçš„ï¼ˆéç©ºç™½ç¬¦ï¼‰
            if start_char == end_char:
                continue
            
            # å°‡å­—å…ƒç´¢å¼•è½‰æ›ç‚º tkinter çš„æ–‡æœ¬ç´¢å¼• (1.0, 1.5, etc.)
            start_index = f"1.0 + {start_char}c"
            end_index = f"1.0 + {end_char}c"

            # æ˜ å°„æå¤±åˆ°é¡è‰²æ¨™ç±¤
            if loss <= q1:
                tag = "low_loss" # ç¶ è‰²ï¼šæ¥µå®¹æ˜“é æ¸¬ (AIå‚¾å‘)
            elif loss <= q2:
                tag = "med_low_loss"
            elif loss <= q3:
                tag = "medium_loss"
            elif loss <= q4:
                tag = "high_loss"
            else:
                tag = "very_high_loss" # ç´…è‰²ï¼šæ¥µé›£é æ¸¬ (äººé¡å‚¾å‘)

            self.input_text.tag_add(tag, start_index, end_index)


    def _calculate_perplexity(self, text):
        """
        æ ¸å¿ƒå›°æƒ‘åº¦è¨ˆç®—é‚è¼¯ï¼Œç¾åœ¨é¡å¤–è¿”å› `offsets` å’Œ `token_losses_np`ã€‚
        """
        # ä½¿ç”¨ return_offsets_mapping=True ä¾†ç²å–æ¯å€‹ Token å°æ‡‰çš„åŸå§‹æ–‡æœ¬å­—å…ƒç¯„åœ
        inputs = self.tokenizer(text, return_tensors="pt", return_offsets_mapping=True)
        input_ids = inputs["input_ids"]
        
        # offsets mapping: [batch_size, seq_len, 2]
        offsets = inputs["offset_mapping"][0].tolist() 

        token_count = input_ids.shape[1] 
        avg_ppl = float('inf')
        var_token_losses = float('inf')
        prediction_text = "ç„¡æ³•åˆ¤æ–· (æ–‡æœ¬éçŸ­æˆ–éŒ¯èª¤)"
        token_losses_np = None # é è¨­ç‚º None

        if token_count <= 1:
            prediction_text = "âš ï¸ è­¦å‘Šï¼šè¼¸å…¥æ–‡æœ¬éçŸ­ï¼Œç„¡æ³•è¨ˆç®—æœ‰æ•ˆçš„å›°æƒ‘åº¦ã€‚"
        else:
            with torch.no_grad():
                outputs = self.model(input_ids, labels=input_ids)
                overall_loss = outputs.loss.item()
                logits = outputs.logits

                shift_logits = logits[:, :-1, :].contiguous()
                shift_labels = input_ids[:, 1:].contiguous()
                
                loss_fct = torch.nn.CrossEntropyLoss(reduction='none')
                token_losses = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))
                token_losses_np = token_losses.detach().cpu().numpy()

                avg_ppl = np.exp(overall_loss)
                var_token_losses = np.var(token_losses_np)

            # åˆ¤æ–·é‚è¼¯ä¸è®Š
            ai_ai_threshold = 30       
            ai_mix_threshold = 100       
            ai_var_loss_threshold = 13 

            if avg_ppl < ai_ai_threshold and var_token_losses < ai_var_loss_threshold:
                prediction_text = "ğŸ¤– æ¥µé«˜å¯èƒ½æ˜¯AIç”Ÿæˆå…§å®¹ (PPLæ¥µä½ï¼Œé«˜åº¦å¯é æ¸¬ä¸”å¹³æ»‘)"
            elif avg_ppl < ai_ai_threshold and var_token_losses >= ai_var_loss_threshold:
                prediction_text = "ğŸ¤– å¯èƒ½æ˜¯AIç”Ÿæˆï¼Œä½†åŒ…å«éå…¸å‹æ¨¡å¼ (PPLä½ï¼Œä½†è©èªé æ¸¬é›£åº¦æ³¢å‹•è¼ƒå¤§)"
            elif avg_ppl >= ai_ai_threshold and avg_ppl < ai_mix_threshold and var_token_losses < ai_var_loss_threshold:
                prediction_text = "ğŸ¤” å¯èƒ½æ˜¯AIç”Ÿæˆæˆ–ç¶“éé«˜åº¦æ½¤é£¾çš„å…§å®¹ (PPLä¸­ç­‰ï¼Œä½†çµæ§‹æ¥µç‚ºå¹³ç©©)"
            elif avg_ppl >= ai_ai_threshold and avg_ppl < ai_mix_threshold and var_token_losses >= ai_var_loss_threshold:
                prediction_text = "âœ… è¼ƒå¯èƒ½æ˜¯äººé¡æ’°å¯« (PPLä¸­ç­‰ï¼Œèªæ°£æˆ–è¡¨é”å…·å‚™è‡ªç„¶æ³¢å‹•)"
            else: 
                prediction_text = "âœ… æ¥µé«˜å¯èƒ½æ˜¯äººé¡æ’°å¯« (PPLé«˜ï¼Œæ¨¡å‹é æ¸¬å›°é›£ï¼Œç¬¦åˆäººé¡å¯«ä½œç‰¹é»)"
        
        # è¿”å›æ‰€æœ‰éœ€è¦çš„æ•¸æ“šï¼ŒåŒ…æ‹¬ç”¨æ–¼é«˜äº®çš„ offsets å’Œ token_losses_np
        return avg_ppl, var_token_losses, token_count, prediction_text, offsets, token_losses_np

if __name__ == "__main__":
    root = tk.Tk()
    app = PerplexityApp(root)
    root.mainloop()